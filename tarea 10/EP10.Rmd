---
title: "Untitled"
output: html_document
date: "`r Sys.Date()`"
---



```{r}
# Importamos las librerías
library(dplyr)
library(ggplot2)
library(EnvStats)
library(ggpubr)
library(tidyverse)
library(car)
library(lmtest)
```



  El equipo crea la variable IMC (índice de masa corporal) como el peso de una persona (en kilogramos) dividida por el cuadrado de su estatura (en metros).
  
Si bien esta variable se usa para clasificar a las personas en varias clases de estado nutricional (bajo peso, normal, sobrepeso, obesidad, obesidad mórbida), para efectos de este ejercicio, usaremos dos clases: sobrepeso (IMC ≥ 23,2) y no sobrepeso (IMC < 23,2).

El equipo crea la variable dicotómica EN (estado nutricional) de acuerdo al valor de IMC de cada persona.
Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:

 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor edad del equipo. 

 2. Seleccionar una muestra de 150 mujeres (si la semilla es un número par) o 150 hombres (si la semilla es impar), asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso” en cada caso. Dividir esta muestra en dos conjuntos: los datos de 100 personas (50 con EN “sobrepeso”) para utilizar en la construcción de los modelos y 50 personas (25 con EN “sobrepeso”) para poder evaluarlos.

 3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.

4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la clase EN, justificando bien esta selección (idealmente con literatura).

5.Usando el entorno R, construir un modelo de regresión logística con el predictor seleccionado en el paso anterior y utilizando de la muestra obtenida.

### 6.Usando estas herramientas para la exploración de modelos del entorno R1, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.

### 7.Evaluar la confiabilidad de los modelos (i.e. que tengan un buen nivel de ajuste y son generalizables) y “arreglarlos” en caso de que tengan algún problema.

### 8.Usando código estándar1, evaluar el poder predictivo de los modelos con los datos de las 50 personas que no se incluyeron en su construcción en términos de sensibilidad y especificidad.


Primero se habrira el archoivo de datos llamdo EP09 Datos.csv y se carga en el data frame llamdo "Datos"

```{r}
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)

```


ahora se define la semilla, y se crea en el data frame una nueva columna que indica el IMC y el EN, para esta ultima se revisa si el IMC es superior a un umbral (23.2), de ser mayor se considera en sobrepeso y en la columna EN, se anota un 1, en caso contrario se considera sin sobrepeso, y se anota un 0, esto se hace para poder trabajar este parametro de mejor manera y evitar posibles complicaciones en un futuro, tambien se crean los conjuntos de prueba y de entrenamiento considerando las condiciones solicitadas.

```{r}
# Definir la semilla
set.seed(5824) # Semilla par, se seleccionan mujeres

#Se crea una nueva columna para cada fila
datos$IMC <- datos$Weight / (datos$Height/100)^2


# Se crea la variable dicotómica EN, (Sobrepeso = 1, No sobrepeso = 0)
datos$EN <- ifelse(datos$IMC >= 23.2, 1, 0)


# Seleccionar una muestra aleatoria de 150 mujeres (si la semilla es un número par)
datos_mujeres_sinsobrepeso <- datos %>%
  filter(Gender == 0, EN==0) %>%
  sample_n(75)

datos_mujeres_consobrepeso <- datos %>%
  filter(Gender == 0, EN==1) %>%
  sample_n(75)

#Separamos los conjuntos de prueba y entrenamiento
m_sinS_prueba <- head(datos_mujeres_sinsobrepeso, 50)
m_conS_prueba <- head(datos_mujeres_consobrepeso, 50)

m_sinS_entrenamiento <- tail(datos_mujeres_sinsobrepeso, 25)
m_conS_entrenamiento <- tail(datos_mujeres_consobrepeso, 25)

#Juntamos los conjuntos de prueba y entrenamiento
datos_prueba <- rbind(m_sinS_prueba, m_conS_prueba)
datos_entrenamiento <- rbind(m_sinS_entrenamiento, m_conS_entrenamiento)

#Creamos una lista con las variables predictoras Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth
variables <- c("Elbows.diameter", "Bitrochanteric.diameter", "Chest.diameter", "Waist.Girth", "Bicep.Girth", "Chest.depth", "Calf.Maximum.Girth", "Navel.Girth")

```

Ahora se crea un modelo de regresion logistica con la variable elegida y uno nulo, la cual fue "Biiliac.diameter", se eligio esta variable debido a que....
```{r}
#Modelo Nulo
modeloNulo <- glm(EN ~ 1, data = datos_entrenamiento, family = binomial)

#usar pero falta justificar de buena manera
modeloSimple <- glm(EN ~ Biiliac.diameter, data = datos_entrenamiento, family = binomial)
summary(modeloSimple)
```

ahora se utilizaran las herramientas presentes en R para seleccionar otras variables predictoras,claramente se elegiran las variables que mas influyan en la prediccion del modelo, sin sobreajustarlo, y sin ningun sesgo en su eleccion, para esto se utilizara las variables que fueron seleccionadas de forma aleatoria en la actividad anterior



```{r}
modelo_completo <- glm(EN ~ Biiliac.diameter + Shoulder.Girth + Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth, data = datos_entrenamiento, family = binomial)

modeloTest <- add1(modeloSimple, scope = modelo_completo)
modeloTest

```
Revisamos los AIC con menor valor y se observa que Bicep.Girth, Navel Girth, Waist.Girth, Shoulder.Girth, Chest.depth son las menores

```{r}
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Bicep.Girth"
modelo_simple2 <- update(modeloSimple, . ~ . + Bicep.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
```

```{r}
#Modificamos el modelo añadiendo el predictor "Navel.Grith"
modelo_simple3 <- update(modelo_simple2, . ~ . + Navel.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
```

```{r}
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
```

```{r}
#Añadimos un predictor más, que sería Shoulder.Girth
modelo_simple5 <- update(modelo_simple4, . ~ . + Shoulder.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4

```

```{r}
#Añadimos un predictor más, que sería Chest.depth
modelo_simple6 <- update(modelo_simple5, . ~ . + Chest.depth)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
```

Se crearon 5 modelos distintos, donde cada uno tiene un predictor más que el anterior, siendo el modelo con más predictores 5 y el con menos el 2. 


```{r}
modeloA <- predict(modelo_simple2, datos_prueba, type = "response")
modeloB <- predict(modelo_simple3, datos_prueba, type = "response")
modeloC <- predict(modelo_simple4, datos_prueba, type = "response")
modeloD <- predict(modelo_simple5, datos_prueba, type = "response")
modeloE <- predict(modelo_simple6, datos_prueba, type = "response")
```

Revisamos porque genera errores de convergencia
```{r}
print(anova(modeloNulo, modelo_simple2, modelo_simple3, modelo_simple4, modelo_simple5, modelo_simple6, test = "LRT"))
`