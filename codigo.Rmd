---
title: "EP14"
output: html_document
date: "`r Sys.Date()`"
---

```{r}
# Importamos las librerías
library(dplyr)
library(ggplot2)
library(EnvStats)
library(ggpubr)
library(tidyverse)
library(car)
```


```{r}
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)

```
# Preguntas

### 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.

### 2. Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar), y separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.

### 3. Seleccionar de forma aleatoria ocho posibles variables predictoras.

### 4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la variable Peso (sin considerar la estatura), justificando bien esta selección.

### 5. Usando el entorno R y paquetes estándares, construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.

### 6. Usando herramientas estándares1 para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.

### 7. Evaluar la bondad de ajuste (incluyendo el análisis de casos atípicos y casos influyentes) y la generalidad (condiciones para RLM) de los modelos y “arreglarlos” en caso de que presenten algún problema.

### 8.Evaluar el poder predictivo del modelo con los datos no utilizados para construirlo.

```{r}
# Definir la semilla
set.seed(8928)

# Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar)
# Separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
datos_mujeres <- datos %>%
  filter(Gender == 0) %>%
  sample_n(100)


# Dividir los datos en conjuntos de entrenamiento y prueba
indices_entrenamiento = sample(1:nrow(datos_mujeres), 0.7 * nrow(datos_mujeres))
datos_entrenamiento = datos_mujeres[indices_entrenamiento, ]
datos_prueba = datos_mujeres[-indices_entrenamiento, ]
```

```{r}
# Definir la semilla
set.seed(8928)
# Seleccionar de forma aleatoria ocho posibles variables predictoras. Descartando altura y la variable peso
variables_predictoras <- colnames(datos_mujeres)[!colnames(datos_mujeres) %in% c("Height", "Weight")]
variables_predictoras <- sample(variables_predictoras, 8)
variables_predictoras


#Vemos las correlaciones de las variables
correlaciones <- cor(datos_mujeres)
print(correlaciones)

```
Shoulder.Girth	Grosor de los hombros sobre los músculos deltoides, sera la variable predictora escogida por el equipo, debido a que, creemos que puede predecir de manera correcta el peso de las personas, ya que al tener más porcetaje de grasa(que aumenta el peso) en el cuerpo, el grosor de los hombros aumenta, espcecialmente en mujeres. En donde no existe tanta musculatura. Además la correlación con la variable peso es bastante alta, con una correlación del 0.8 aproximadamente.

```{r}
# Construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
modelo_simple <- lm(Weight ~ Shoulder.Girth, data = datos_entrenamiento) #Modelo Nulo
summary(modelo_simple)
```
Como se puede ver, el modelo es bastante bueno, prediciendo la variable peso con estimado del 1.19 lo que nos dice, por cada cm de Grosor de Hombro se aumenta un 1.19kg, un error del 0.1, un t value del 11.42 y un p value de 2e-16, lo que nos dice que es muy significativo.


Ahora, para encontrar los predictores que se pueden agregar al modelo, se puede hacer un análisis de regresión múltiple, para ver que variables son las que más influyen en el peso de las personas. Usaremos el metodo de selección hacia adelante que es una buena elección cuando se busca construir un modelo predictivo, especialmente cuando hay muchas variables iniciales y se sospecha que solo unas pocas son relevantes 

```{r}
# Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.

#Ajustamos el modelo completo con "Elbows.diameter" "Bitrochanteric.diameter" "Chest.diameter" "Waist.Girth" "Bicep.Girth" "Chest.depth" "Calf.Maximum.Girth" "Navel.Girth"
modelo_completo <- lm(Weight ~ Shoulder.Girth + Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth, data = datos_entrenamiento)
summary(modelo_completo)
```

```{r}
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
modelo_termina
```
revisamos los AIC y vemos cual es el menor, solo agregar el menor con update, repetir un par de veces.

condiciones para generalizar el modelo (cambiar nombres eh interpretar datos solamente)


```{r}

# 1. Las variables predictoras deben ser cuantitativas o dicotómicas

# 2. La variable de respuesta debe ser cuantitativa y continua

# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Elbows.diameter", "Bitrochanteric.diameter", "Chest.diameter", "Waist.Girth","Bicep.Girth","Chest.depth", "Calf.Maximum.Girth","Navel.Girth" )], var)
cat("\n")
cat("\n")

# Como todas las varianzas de los predictores son distintas a cero podemos continuar.

# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_termina)
cat("\n")
cat("\n")

# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.

# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_termina, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_termina)
cat("\n")

# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.

# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_termina), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_termina))

# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.

# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente

# 8. Cada predictor se relaciona linealmente con la variable de respuesta

# Felicidad con N_mascotas
ggscatter(datos_entrenamiento, x = "Felicidad", y = "N_mascotas", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).

# N_amigos con N_mascotas
ggscatter(datos_entrenamiento, x = "N_amigos", y = "N_mascotas", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).

# Sexo con N_mascotas
ggscatter(datos_entrenamiento, x = "Sexo", y = "N_mascotas", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).

# Edad con N_mascotas
ggscatter(datos_entrenamiento, x = "Edad", y = "N_mascotas", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal negativa muy débil, ya que, su valor R (-0.043) se encuentra entre 0 y -0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.73) es mayor al nivel de significancia alpha (0.05).
```


```{r}
predicciones_inicial <- predict(modelo_inicial, newdata = datos_probar_modelo)

mse_inicial <- mean((datos_probar_modelo$N_mascotas - predicciones_inicial)^2)
```



```{r}
# Evaluar el R-cuadrado y R-cuadrado ajustado del modelo
summary(modelo_termina)$r.squared
summary(modelo_termina)$adj.r.squared
```

