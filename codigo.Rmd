---
title: "EP14"
output: html_document
date: "`r Sys.Date()`"
---

```{r}
# Importamos las librerías
library(dplyr)
library(ggplot2)
library(EnvStats)
library(ggpubr)
library(tidyverse)
library(car)
library(lmtest)
```


```{r}
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)

```
# Preguntas

### 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.

### 2. Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar), y separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.

### 3. Seleccionar de forma aleatoria ocho posibles variables predictoras.

### 4. Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la variable Peso (sin considerar la estatura), justificando bien esta selección.

### 5. Usando el entorno R y paquetes estándares, construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.

### 6. Usando herramientas estándares1 para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.

### 7. Evaluar la bondad de ajuste (incluyendo el análisis de casos atípicos y casos influyentes) y la generalidad (condiciones para RLM) de los modelos y “arreglarlos” en caso de que presenten algún problema.

### 8.Evaluar el poder predictivo del modelo con los datos no utilizados para construirlo.

```{r}
# Definir la semilla
set.seed(8928)

# Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar)
# Separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
datos_mujeres <- datos %>%
  filter(Gender == 0) %>%
  sample_n(100)


# Dividir los datos en conjuntos de entrenamiento y prueba
indices_entrenamiento = sample(1:nrow(datos_mujeres), 0.7 * nrow(datos_mujeres))
datos_entrenamiento = datos_mujeres[indices_entrenamiento, ]
datos_prueba = datos_mujeres[-indices_entrenamiento, ]
```

```{r}
# Definir la semilla
set.seed(8928)
# Seleccionar de forma aleatoria ocho posibles variables predictoras. Descartando altura y la variable peso
variables_predictoras <- colnames(datos_mujeres)[!colnames(datos_mujeres) %in% c("Height", "Weight")]
variables_predictoras <- sample(variables_predictoras, 8)
variables_predictoras


#Vemos las correlaciones de las variables
correlaciones <- cor(datos_mujeres)
print(correlaciones)

```
Shoulder.Girth	Grosor de los hombros sobre los músculos deltoides, sera la variable predictora escogida por el equipo, debido a que, creemos que puede predecir de manera correcta el peso de las personas, ya que al tener más porcetaje de grasa(que aumenta el peso) en el cuerpo, el grosor de los hombros aumenta, espcecialmente en mujeres. En donde no existe tanta musculatura. Además la correlación con la variable peso es bastante alta, con una correlación del 0.8 aproximadamente.

```{r}
# Construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
modelo_simple <- lm(Weight ~ Shoulder.Girth, data = datos_entrenamiento) #Modelo Nulo
summary(modelo_simple)
```
Como se puede ver, el modelo es bastante bueno, prediciendo la variable peso con estimado del 1.19 lo que nos dice, por cada cm de Grosor de Hombro se aumenta un 1.19kg, un error del 0.1, un t value del 11.42 y un p value de 2e-16, lo que nos dice que es muy significativo.


Ahora, para encontrar los predictores que se pueden agregar al modelo, se puede hacer un análisis de regresión múltiple, para ver que variables son las que más influyen en el peso de las personas. Usaremos el metodo de selección hacia adelante que es una buena elección cuando se busca construir un modelo predictivo, especialmente cuando hay muchas variables iniciales y se sospecha que solo unas pocas son relevantes 

```{r}
# Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.

#Ajustamos el modelo completo con "Elbows.diameter" "Bitrochanteric.diameter" "Chest.diameter" "Waist.Girth" "Bicep.Girth" "Chest.depth" "Calf.Maximum.Girth" "Navel.Girth"
modelo_completo <- lm(Weight ~ Shoulder.Girth + Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth, data = datos_entrenamiento)
summary(modelo_completo)
```

```{r}
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
modelo_termina
```
revisamos los AIC y vemos cual es el menor, solo agregar el menor con update, repetir un par de veces.



```{r}
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Navel.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
```

```{r}
#Añadimos un predictor más, que sería Calf.Maximum.Girth
modelo_simple3 <- update(modelo_simple2, . ~ . + Calf.Maximum.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
```

```{r}
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4

```

```{r}
#Añadimos un predictor más, que sería Bitrochanteric.diameter
modelo_simple5 <- update(modelo_simple4, . ~ . + Bitrochanteric.diameter)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
```

Se crearon 4 modelos distintos, donde cada uno tiene un predictor más que el anterior, siendo el modelo con más predictores 5 y el con menos 2. 


## Bondad de ajuste


Evaluamos la bondad de ajuste
```{r}
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
```

```{r}
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
```


Como podemos ver, el que explica más varianza y tiene menor AIC y BIC es el modelo 5, por lo que es el que se escogerá para hacer las predicciones.

```{r}
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas 
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)

# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1

# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2



```
Como se puede apreciar, no existen valores atipicos en el modelo, por lo que no se deben eliminar valores.



Condiciones para generalizar el modelo: 

```{r}

# 1. Las variables predictoras deben ser cuantitativas o dicotómicas

# 2. La variable de respuesta debe ser cuantitativa y continua

# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Bitrochanteric.diameter", "Waist.Girth", "Calf.Maximum.Girth","Navel.Girth", "Shoulder.Girth" )], var)
cat("\n")
cat("\n")

# Como todas las varianzas de los predictores son distintas a cero podemos continuar.

# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_simple5)
cat("\n")
cat("\n")

# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.

# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_simple5, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_simple5)
cat("\n")

# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.

# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_simple5), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_simple5))

# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.

# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente

# 8. Cada predictor se relaciona linealmente con la variable de respuesta




# Bitrochanteric.diameter con Weight
ggscatter(datos_entrenamiento, x = "Bitrochanteric.diameter", y = "Weight", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).

# Waist.Girth con Weight
ggscatter(datos_entrenamiento, x = "Waist.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).

# Calf.Maximum.Girth con Weight
ggscatter(datos_entrenamiento, x = "Calf.Maximum.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).

# Navel.Girth con Weight
ggscatter(datos_entrenamiento, x = "Navel.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")

# Shoulder.Girth con Weight
ggscatter(datos_entrenamiento, x = "Shoulder.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) + 
  stat_cor(method = "pearson")


```
Como se puede ver, se cumplen todas las condiciones, por lo que se puede generalizar el modelo

```{r}
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)

mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial

```
Aqui se puede apreciar que el mse es de 11.19, por lo tanto existe un margen de error de 11.19

```{r}
summary(modelo_simple5)
```
como se puede apreciar el p-value es bajisimo, lo cual nos dice que el modelo en cuestion es altamente significativo, ademas el valor de R-squared el cual es del 0.9121 significa que mas del 90% de la variabilidad es explicada con el modelo creado. 
