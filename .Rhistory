summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)
# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1
# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2
# 1. Las variables predictoras deben ser cuantitativas o dicotómicas
# 2. La variable de respuesta debe ser cuantitativa y continua
# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Bitrochanteric.diameter", "Waist.Girth", "Calf.Maximum.Girth","Navel.Girth", "Shoulder.Girth" )], var)
cat("\n")
cat("\n")
# Como todas las varianzas de los predictores son distintas a cero podemos continuar.
# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_simple5)
cat("\n")
cat("\n")
# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.
# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_simple5, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_simple5)
cat("\n")
# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.
# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_simple5), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_simple5))
# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.
# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente
# 8. Cada predictor se relaciona linealmente con la variable de respuesta
# Bitrochanteric.diameter con Weight
ggscatter(datos_entrenamiento, x = "Bitrochanteric.diameter", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).
# Waist.Girth con Weight
ggscatter(datos_entrenamiento, x = "Waist.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).
# Calf.Maximum.Girth con Weight
ggscatter(datos_entrenamiento, x = "Calf.Maximum.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).
# Navel.Girth con Weight
ggscatter(datos_entrenamiento, x = "Navel.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Shoulder.Girth con Weight
ggscatter(datos_entrenamiento, x = "Shoulder.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)
mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial
summary(modelo_simple5)
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)
# Definir la semilla
set.seed(8928)
# Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar)
# Separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
datos_mujeres <- datos %>%
filter(Gender == 0) %>%
sample_n(100)
# Dividir los datos en conjuntos de entrenamiento y prueba
indices_entrenamiento = sample(1:nrow(datos_mujeres), 0.7 * nrow(datos_mujeres))
datos_entrenamiento = datos_mujeres[indices_entrenamiento, ]
datos_prueba = datos_mujeres[-indices_entrenamiento, ]
# Definir la semilla
set.seed(8928)
# Seleccionar de forma aleatoria ocho posibles variables predictoras. Descartando altura y la variable peso
variables_predictoras <- colnames(datos_mujeres)[!colnames(datos_mujeres) %in% c("Height", "Weight")]
variables_predictoras <- sample(variables_predictoras, 8)
variables_predictoras
#Vemos las correlaciones de las variables
correlaciones <- cor(datos_mujeres)
print(correlaciones)
# Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.
#Ajustamos el modelo completo con "Elbows.diameter" "Bitrochanteric.diameter" "Chest.diameter" "Waist.Girth" "Bicep.Girth" "Chest.depth" "Calf.Maximum.Girth" "Navel.Girth"
modelo_completo <- lm(Weight ~ Shoulder.Girth + Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth, data = datos_entrenamiento)
summary(modelo_completo)
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
modelo_termina
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + bicep.Girth)
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Bicep.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
#Añadimos un predictor más, que sería Calf.Maximum.Girth
modelo_simple3 <- update(modelo_simple2, . ~ . + Calf.Maximum.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4
#Añadimos un predictor más, que sería Bitrochanteric.diameter
modelo_simple5 <- update(modelo_simple4, . ~ . + Bitrochanteric.diameter)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)
# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1
# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2
# 1. Las variables predictoras deben ser cuantitativas o dicotómicas
# 2. La variable de respuesta debe ser cuantitativa y continua
# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Bitrochanteric.diameter", "Waist.Girth", "Calf.Maximum.Girth","Navel.Girth", "Shoulder.Girth" )], var)
cat("\n")
cat("\n")
# Como todas las varianzas de los predictores son distintas a cero podemos continuar.
# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_simple5)
cat("\n")
cat("\n")
# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.
# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_simple5, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_simple5)
cat("\n")
# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.
# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_simple5), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_simple5))
# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.
# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente
# 8. Cada predictor se relaciona linealmente con la variable de respuesta
# Bitrochanteric.diameter con Weight
ggscatter(datos_entrenamiento, x = "Bitrochanteric.diameter", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).
# Waist.Girth con Weight
ggscatter(datos_entrenamiento, x = "Waist.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).
# Calf.Maximum.Girth con Weight
ggscatter(datos_entrenamiento, x = "Calf.Maximum.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).
# Navel.Girth con Weight
ggscatter(datos_entrenamiento, x = "Navel.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Shoulder.Girth con Weight
ggscatter(datos_entrenamiento, x = "Shoulder.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)
mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial
summary(modelo_simple5)
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Chest.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
modelo_termina
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Chest.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . +Chest.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . +Chest.diameter)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
#Añadimos un predictor más, que sería Calf.Maximum.Girth
modelo_simple3 <- update(modelo_simple2, . ~ . + Calf.Maximum.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4
#Añadimos un predictor más, que sería Bitrochanteric.diameter
modelo_simple5 <- update(modelo_simple4, . ~ . + Bitrochanteric.diameter)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)
# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1
# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)
mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Chest.depth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
#Añadimos un predictor más, que sería Calf.Maximum.Girth
modelo_simple3 <- update(modelo_simple2, . ~ . + Calf.Maximum.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4
#Añadimos un predictor más, que sería Bitrochanteric.diameter
modelo_simple5 <- update(modelo_simple4, . ~ . + Bitrochanteric.diameter)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)
# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1
# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2
# 1. Las variables predictoras deben ser cuantitativas o dicotómicas
# 2. La variable de respuesta debe ser cuantitativa y continua
# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Bitrochanteric.diameter", "Waist.Girth", "Calf.Maximum.Girth","Navel.Girth", "Shoulder.Girth" )], var)
cat("\n")
cat("\n")
# Como todas las varianzas de los predictores son distintas a cero podemos continuar.
# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_simple5)
cat("\n")
cat("\n")
# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.
# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_simple5, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_simple5)
cat("\n")
# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.
# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_simple5), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_simple5))
# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.
# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente
# 8. Cada predictor se relaciona linealmente con la variable de respuesta
# Bitrochanteric.diameter con Weight
ggscatter(datos_entrenamiento, x = "Bitrochanteric.diameter", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).
# Waist.Girth con Weight
ggscatter(datos_entrenamiento, x = "Waist.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).
# Calf.Maximum.Girth con Weight
ggscatter(datos_entrenamiento, x = "Calf.Maximum.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).
# Navel.Girth con Weight
ggscatter(datos_entrenamiento, x = "Navel.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Shoulder.Girth con Weight
ggscatter(datos_entrenamiento, x = "Shoulder.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)
mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
# Importamos las librerías
library(dplyr)
library(ggplot2)
library(EnvStats)
library(ggpubr)
library(tidyverse)
library(car)
library(lmtest)
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)
# Definir la semilla
set.seed(8928)
# Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar)
# Separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
datos_mujeres <- datos %>%
filter(Gender == 0) %>%
sample_n(100)
# Dividir los datos en conjuntos de entrenamiento y prueba
indices_entrenamiento = sample(1:nrow(datos_mujeres), 0.7 * nrow(datos_mujeres))
datos_entrenamiento = datos_mujeres[indices_entrenamiento, ]
datos_prueba = datos_mujeres[-indices_entrenamiento, ]
# Definir la semilla
set.seed(8928)
# Seleccionar de forma aleatoria ocho posibles variables predictoras. Descartando altura y la variable peso
variables_predictoras <- colnames(datos_mujeres)[!colnames(datos_mujeres) %in% c("Height", "Weight")]
variables_predictoras <- sample(variables_predictoras, 8)
variables_predictoras
#Vemos las correlaciones de las variables
correlaciones <- cor(datos_mujeres)
print(correlaciones)
# Construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
modelo_simple <- lm(Weight ~ Shoulder.Girth, data = datos_entrenamiento) #Modelo Nulo
summary(modelo_simple)
# Usando herramientas estándares para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.
#Ajustamos el modelo completo con "Elbows.diameter" "Bitrochanteric.diameter" "Chest.diameter" "Waist.Girth" "Bicep.Girth" "Chest.depth" "Calf.Maximum.Girth" "Navel.Girth"
modelo_completo <- lm(Weight ~ Shoulder.Girth + Elbows.diameter + Bitrochanteric.diameter + Chest.diameter + Waist.Girth + Bicep.Girth + Chest.depth + Calf.Maximum.Girth + Navel.Girth, data = datos_entrenamiento)
summary(modelo_completo)
modelo_termina <- add1(modelo_simple, scope = modelo_completo)
modelo_termina
#Modificamos el modelo añadiendo el predictor que nos dio el menor AIC, "Navel.Grith"
modelo_simple2 <- update(modelo_simple, . ~ . + Navel.Girth)
AIC_2 <- add1(modelo_simple2, scope = modelo_completo)
AIC_2
#Añadimos un predictor más, que sería Calf.Maximum.Girth
modelo_simple3 <- update(modelo_simple2, . ~ . + Calf.Maximum.Girth)
AIC_3 <- add1(modelo_simple3, scope = modelo_completo)
AIC_3
#Añadimos un predictor más, que sería Waist.Girth
modelo_simple4 <- update(modelo_simple3, . ~ . + Waist.Girth)
AIC_4 <- add1(modelo_simple4, scope = modelo_completo)
AIC_4
#Añadimos un predictor más, que sería Bitrochanteric.diameter
modelo_simple5 <- update(modelo_simple4, . ~ . + Bitrochanteric.diameter)
AIC_5 <- add1(modelo_simple5, scope = modelo_completo)
AIC_5
# Evaluar el R-cuadrado ajustado de cada modelo
summary(modelo_simple2)$adj.r.squared
summary(modelo_simple3)$adj.r.squared
summary(modelo_simple4)$adj.r.squared
summary(modelo_simple5)$adj.r.squared
# Evaluar el AIC y BIC de cada modelo
AIC(modelo_simple2)
BIC(modelo_simple2)
AIC(modelo_simple3)
BIC(modelo_simple3)
AIC(modelo_simple4)
BIC(modelo_simple4)
AIC(modelo_simple5)
BIC(modelo_simple5)
#Análisis de casos atípicos con cook, apalancamiento, residuos estandarizados y studentizados, dffits y dfbetas
cooks_distance <- cooks.distance(modelo_simple5)
leverage <- hatvalues(modelo_simple5)
resid_standard <- rstandard(modelo_simple5)
resid_student <- rstudent(modelo_simple5)
dffits_values <- dffits(modelo_simple5)
dfbetas_values <- dfbeta(modelo_simple5)
# Observaciones con distancia de Cook mayor a 0.5.
sospechosos1 <- which(abs(cooks_distance) > 0.5)
sospechosos1
# Observaciones con apalancamiento mayor a 2(p+1)/n
apal_medio <- (ncol(datos_entrenamiento) + 1) / nrow(datos_entrenamiento)
sospechosos2 <- which(abs(leverage) > 2 * apal_medio)
sospechosos2
# 1. Las variables predictoras deben ser cuantitativas o dicotómicas
# 2. La variable de respuesta debe ser cuantitativa y continua
# 3. Los predictores deben tener algún grado de variabilidad
cat("Calculo de varianza de los predictores \n\n")
sapply(datos_entrenamiento[, c("Bitrochanteric.diameter", "Waist.Girth", "Calf.Maximum.Girth","Navel.Girth", "Shoulder.Girth" )], var)
cat("\n")
cat("\n")
# Como todas las varianzas de los predictores son distintas a cero podemos continuar.
# 4. No debe existir multicolinealidad
cat("Calculo de la multicolinealidad \n\n")
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
vif(modelo_simple5)
cat("\n")
cat("\n")
# Como todos los VIF son menores a 5 y cercanos a 1 podemos afirmar que no existe multicolinealidad.
# 5. Los residuos deben ser homocedásticos
cat("Comprobación de la homocedásticidad de los residuos \n")
plot(modelo_simple5, which = 1)
# cambiar model_termina por el modelo final(no se puede usar el modelo obtenido por add1, hay que hacerlo a mano)
bptest(modelo_simple5)
cat("\n")
# Como el p valor entregado por la prueba de Breusch-Pagan es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos son homocedásticos.
# 6. Los residuos deben seguir una distribución cercana a la normal centrada en cero
cat("Comprobación de la normalidad \n")
hist(residuals(modelo_simple5), breaks = 10, main = "Histograma de Residuos", xlab = "Residuos")
shapiro.test(residuals(modelo_simple5))
# Como el p valor entregado por la prueba de Shapiro es menor a el nivel de significancia alpha (0.05), podemos afirmar que los residuos siguen una distribución normal.
# 7. Los valores de la variable de respuesta son independientes entre sí
# Asumimos que la recolección de datos fue independiente
# 8. Cada predictor se relaciona linealmente con la variable de respuesta
# Bitrochanteric.diameter con Weight
ggscatter(datos_entrenamiento, x = "Bitrochanteric.diameter", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.29) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.014) es menor al nivel de significancia alpha (0.05).
# Waist.Girth con Weight
ggscatter(datos_entrenamiento, x = "Waist.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva muy débil, ya que, su valor R (0.18) se encuentra entre 0 y 0.2. Ademas,  podemos asumir que la correlación observada no es significativa, ya que, su valor p (0.14) es mayor al nivel de significancia alpha (0.05).
# Calf.Maximum.Girth con Weight
ggscatter(datos_entrenamiento, x = "Calf.Maximum.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Para esta relación podemos asumir que es una lineal positiva débil, ya que, su valor R (0.32) se encuentra entre 0.2 y 0.4. Ademas,  podemos asumir que la correlación observada es significativa, ya que, su valor p (0.007) es menor al nivel de significancia alpha (0.05).
# Navel.Girth con Weight
ggscatter(datos_entrenamiento, x = "Navel.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
# Shoulder.Girth con Weight
ggscatter(datos_entrenamiento, x = "Shoulder.Girth", y = "Weight", add = "reg.line", conf.int = TRUE) +
stat_cor(method = "pearson")
predicciones_inicial <- predict(modelo_simple5, newdata = datos_prueba)
mse_inicial <- mean((datos_prueba$Weight - predicciones_inicial)^2)
mse_inicial
summary(modelo_simple5)
