---
title: "EP11"
author: "Nicolas salinas"
date: "2024-08-11"
output: html_document
---

Para este ejercicio usaremos los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya hemos utilizado en los ejercicios prácticos anteriores (disponibles en el archivo "EP09 Datos.csv"), con la adición de las variables IMC y EN consideradas en el ejercicio práctico anterior.

En este contexto realizaremos las siguientes actividades:

### Definir la semilla a utilizar, que corresponde a los primeros cinco dígitos del RUN del integrante de mayor edad del equipo.

### Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.

### Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.

### Haciendo un poco de investigación sobre el paquete caret, en particular cómo hacer Recursive Feature Elimination (RFE), construir un modelo de regresión lineal múltiple para predecir la variable IMC que incluya entre 10 y 20 predictores, seleccionando el conjunto de variables que maximice R2 y que use cinco repeticiones de validación cruzada de cinco pliegues para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura ni estado nutricional –Weight, Height, EN respectivamente).

### Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto, de entre dos y seis, predictores que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).

### Pronunciarse sobre la confiabilidad y el poder predictivo de los modelos obtenidos.



```{r}
# Importamos las librerías
library(dplyr)
library(ggplot2)
library(EnvStats)
library(ggpubr)
library(tidyverse)
library(car)
library(lmtest)
library(psych)
library(ggfortify)
library(leaps)
# library(caret)
library(boot)


```






para realizar la actividad propuesta, en primera instancia se leeran los datos

```{r}
# Lectura de archivo
# Se abre el CSV, cambiar la ruta según corresponda
nombre_archivo <- "EP09 Datos.csv"
datos <- read.csv2(nombre_archivo)

```

luego a los datos almacenados en la variable "Datos" se les añade la columna  "IMC", y "EN", en esta ultima guardando una variable dicotomica la cual si es 1 indica que la persona tiene sobrepeso, si es un 0, indica que la persona no tiene sobrepeso

```{r}
# Definir la semilla
set.seed(5824) # Semilla par, se seleccionan mujeres

#Se crea una nueva columna para cada fila
datos$IMC <- datos$Weight / (datos$Height/100)^2


# Se crea la variable dicotómica EN, (Sobrepeso = 1, No sobrepeso = 0)
datos$EN <- ifelse(datos$IMC >= 23.2, 1, 0)

```

ahora se procede a seleccionar la muestra de 100 personas claramente respetando la condicion de que la mitad deban tener un estado nutricional "sobrepeso" y la otra mitad "no sobrepeso", esto en el contexto de la variable añadida "EN", resulta en que la mitad tengan un EN = 1 y la otra mitad un EN = 0
```{r}
# Seleccionar una muestra aleatoria de 150 mujeres (si la semilla es un número par)
datos_sin_sobrepeso <- datos %>%
  filter( EN==0) %>%
  sample_n(50)

datos_con_sobrepeso <- datos %>%
  filter( EN==1) %>%
  sample_n(50)

datos_Prueba <- rbind(datos_con_sobrepeso, datos_sin_sobrepeso)

#Desordenamos los datos con sample
datos_Prueba <- datos_Prueba[sample(nrow(datos_Prueba)),]

```


una vez se tienen los datos ya preparados y desordenados, toca elegir los predictores para lo cual se utilizara la libreria "leaps", para obtener los mejores predictores

```{r}
# (Excluyendo las variables IMC y EN)
variables_lineales <- setdiff(names(datos_Prueba), c("Weight", "IMC", "EN"))

# Selección de predictores usando regsubsets
leaps_model <- regsubsets(Weight ~ ., data = datos_Prueba[ , c("Weight", variables_lineales)], 
                          nbest = 1, nvmax = 8, method = "exhaustive")

# Obtener los mejores predictores (selección entre 2 y 8)
summary_leaps <- summary(leaps_model)
best_predictors <- names(coef(leaps_model, which.min(summary_leaps$cp))[-1])
```

ahora se construira un modelo de regresion lineal multiple usando los predictores obtenidos del paso anterior. y usando la libreria "caret"

```{r}
# Construcción del modelo de regresión lineal múltiple con caret
control <- trainControl(method = "boot", number = 100)
model_lm <- train(Weight ~ ., data = muestra[ , c("Weight", best_predictors)],
                  method = "lm", trControl = control)
```




